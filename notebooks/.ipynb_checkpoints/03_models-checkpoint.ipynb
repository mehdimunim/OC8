{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38dc5d5-9042-40f4-bcdf-391f82bd3f46",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c7cc43-00be-49e4-be07-461c19ed3957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:31:58.634696Z",
     "iopub.status.busy": "2025-02-28T13:31:58.634204Z",
     "iopub.status.idle": "2025-02-28T13:32:02.905945Z",
     "shell.execute_reply": "2025-02-28T13:32:02.904706Z",
     "shell.execute_reply.started": "2025-02-28T13:31:58.634643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 14:31:59.894126: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-28 14:31:59.899356: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-28 14:31:59.914921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740749519.941808   18593 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740749519.948603   18593 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-28 14:31:59.972766: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6c8e0-8a57-47c9-8921-b294b08a839c",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e2c7ba-f4ef-46b8-9504-a78b42fecd9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:02.911294Z",
     "iopub.status.busy": "2025-02-28T13:32:02.910555Z",
     "iopub.status.idle": "2025-02-28T13:32:02.917293Z",
     "shell.execute_reply": "2025-02-28T13:32:02.916172Z",
     "shell.execute_reply.started": "2025-02-28T13:32:02.911256Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 512\n",
    "NUM_CLASSES = 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b631a4-0474-460f-bffc-33d31db89ed8",
   "metadata": {},
   "source": [
    "# Chargement des chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6faea67b-9985-4fcb-bef5-815c3bc247bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:02.919371Z",
     "iopub.status.busy": "2025-02-28T13:32:02.918936Z",
     "iopub.status.idle": "2025-02-28T13:32:02.978334Z",
     "shell.execute_reply": "2025-02-28T13:32:02.977212Z",
     "shell.execute_reply.started": "2025-02-28T13:32:02.919318Z"
    }
   },
   "outputs": [],
   "source": [
    "images_path = sorted(glob.glob(\"../data/raw/leftImg8bit/train/*/*.png\"))\n",
    "masks_path = sorted(glob.glob(\"../data/raw/gtFine/train/*/*gtFine_labelIds.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423fa32-4590-4d8b-aa77-7ceab58f3d7f",
   "metadata": {},
   "source": [
    "# Class Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d24f643-dc49-45af-b942-04df015faf5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:02.979817Z",
     "iopub.status.busy": "2025-02-28T13:32:02.979275Z",
     "iopub.status.idle": "2025-02-28T13:32:02.989224Z",
     "shell.execute_reply": "2025-02-28T13:32:02.987781Z",
     "shell.execute_reply.started": "2025-02-28T13:32:02.979779Z"
    }
   },
   "outputs": [],
   "source": [
    "new_class_mapping = {\n",
    "    0: 0,    # 'unlabeled'            -> background\n",
    "    1: 0,    # 'ego vehicle'          -> background\n",
    "    2: 0,    # 'rectification border' -> background\n",
    "    3: 0,    # 'out of roi'           -> background\n",
    "    4: 0,    # 'static'               -> background\n",
    "    5: 0,    # 'dynamic'              -> background\n",
    "    6: 0,    # 'ground'               -> background\n",
    "    7: 1,    # 'road'         -> flat\n",
    "    8: 2,    # 'sidewalk'            -> flat\n",
    "    9: 0,    # 'parking'              -> background\n",
    "    10: 0,   # 'rail track'           -> background\n",
    "    11: 3,   # 'building'             -> construction\n",
    "    12: 0,   # 'wall'         -> construction\n",
    "    13: 8,   # 'fence'                -> construction\n",
    "    14: 0,   # 'guard rail'           -> background\n",
    "    15: 0,   # 'bridge'               -> background\n",
    "    16: 0,   # 'tunnel'               -> background\n",
    "    17: 0,    # 'pole'          -> object\n",
    "    18: 0,    # 'polegroup'            -> object\n",
    "    19: 0,    # 'traffic light'        -> object\n",
    "    20: 0,    # 'traffic sign'         -> object\n",
    "    21: 4,   # 'vegetation'           -> nature\n",
    "    22: 0,   # 'terrain'              -> nature\n",
    "    23: 5,   # 'sky'                  -> sky\n",
    "    24: 6,   # 'person'               -> human\n",
    "    25: 6,   # 'rider'                -> human\n",
    "    26: 7,   # 'car'                  -> vehicle\n",
    "    27: 7,   # 'truck'                -> vehicle\n",
    "    28: 7,   # 'bus'                  -> vehicle\n",
    "    29: 7,   # 'caravan'              -> vehicle\n",
    "    30: 7,   # 'trailer'              -> vehicle\n",
    "    31: 7,   # 'train'                -> vehicle\n",
    "    32: 7,   # 'motorcycle'           -> vehicle\n",
    "    33: 7,   # 'bicycle'              -> vehicle\n",
    "    -1: 0     # 'license plate'        -> background\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce05f8f-01ae-4d27-9f65-ece769545009",
   "metadata": {},
   "source": [
    "# Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad20fda0-1925-4ec9-985e-6e673d87c4c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:02.991151Z",
     "iopub.status.busy": "2025-02-28T13:32:02.990314Z",
     "iopub.status.idle": "2025-02-28T13:32:03.013462Z",
     "shell.execute_reply": "2025-02-28T13:32:03.012311Z",
     "shell.execute_reply.started": "2025-02-28T13:32:02.991107Z"
    }
   },
   "outputs": [],
   "source": [
    "def remap_classes(mask, mapping):\n",
    "    remapped_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for old_class, new_class in mapping.items():\n",
    "        remapped_mask[mask == old_class] = new_class\n",
    "    return remapped_mask\n",
    "\n",
    "def get_city_name(image_path):\n",
    "    return image_path.split('/')[-2]\n",
    "\n",
    "def get_image_name(image_path):\n",
    "    return image_path.split('/')[-1].split('_leftImg8bit')[0]\n",
    "\n",
    "def load_and_preprocess_image(image_path, mask_path, class_mapping, img_height, img_width):\n",
    "    # Load image and mask\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Resize\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    mask = cv2.resize(mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Normalize image\n",
    "    image = image.astype(\"float32\") / 255.0\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb52357f-e30d-49af-933f-bc2f927e76cb",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73897d4a-6d58-427f-9a19-e9dd51ae4fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:03.014795Z",
     "iopub.status.busy": "2025-02-28T13:32:03.014403Z",
     "iopub.status.idle": "2025-02-28T13:32:03.050339Z",
     "shell.execute_reply": "2025-02-28T13:32:03.049367Z",
     "shell.execute_reply.started": "2025-02-28T13:32:03.014763Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, images_path, masks_path, batch_size, img_height, img_width, num_classes):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.batch_size = batch_size\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.num_classes = num_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.images_path) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx + 1) * self.batch_size\n",
    "\n",
    "        batch_images_path = self.images_path[start:end]\n",
    "        batch_masks_path = self.masks_path[start:end]\n",
    "\n",
    "        batch_images = []\n",
    "        batch_masks = []\n",
    "\n",
    "        for i in range(len(batch_images_path)):\n",
    "            image, mask = load_and_preprocess_image(batch_images_path[i], batch_masks_path[i], new_class_mapping, self.img_height, self.img_width)\n",
    "            batch_images.append(image)\n",
    "            batch_masks.append(mask)\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_masks = np.array(batch_masks)\n",
    "\n",
    "        batch_masks = np.expand_dims(batch_masks, -1)\n",
    "        batch_masks = tf.keras.utils.to_categorical(batch_masks, num_classes=self.num_classes)\n",
    "        \n",
    "        return batch_images, batch_masks\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Optionally shuffle the data at the end of each epoch\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8539a7c-2ff9-4d19-bc83-949cafa41e20",
   "metadata": {},
   "source": [
    "# Modèle UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb95dd9-1886-411a-8a7e-d25e342fa23c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:03.052109Z",
     "iopub.status.busy": "2025-02-28T13:32:03.051636Z",
     "iopub.status.idle": "2025-02-28T13:32:03.067523Z",
     "shell.execute_reply": "2025-02-28T13:32:03.066457Z",
     "shell.execute_reply.started": "2025-02-28T13:32:03.052072Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_unet(img_height, img_width, num_classes):\n",
    "    inputs = keras.layers.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = keras.layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = keras.layers.MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv3 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = keras.layers.UpSampling2D((2, 2))(conv3)\n",
    "    merge4 = keras.layers.concatenate([conv2, up4], axis=-1)\n",
    "    conv4 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(merge4)\n",
    "\n",
    "    up5 = keras.layers.UpSampling2D((2, 2))(conv4)\n",
    "    merge5 = keras.layers.concatenate([conv1, up5], axis=-1)\n",
    "    conv5 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(merge5)\n",
    "\n",
    "    # Output\n",
    "    outputs = keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(conv5)\n",
    "\n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f35da-d6b5-40a8-b3a6-96193b16b3e2",
   "metadata": {},
   "source": [
    "# Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac693ed-3d71-4685-b9c3-0cf1b68b32d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:03.072232Z",
     "iopub.status.busy": "2025-02-28T13:32:03.070001Z",
     "iopub.status.idle": "2025-02-28T13:32:07.179615Z",
     "shell.execute_reply": "2025-02-28T13:32:07.178050Z",
     "shell.execute_reply.started": "2025-02-28T13:32:03.072090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 14:32:03.099237: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/mehdi/Documents/OC/OC8/.venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 23 is out of bounds for axis 1 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Building and Training Complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/OC/OC8/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m, in \u001b[0;36mDataGenerator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m batch_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(batch_masks, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[0;32m---> 34\u001b[0m batch_masks \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_images, batch_masks\n",
      "\u001b[0;31mIndexError\u001b[0m: index 23 is out of bounds for axis 1 with size 9"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = build_unet(IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators\n",
    "train_generator = DataGenerator(images_path, masks_path, batch_size, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES)\n",
    "val_generator = DataGenerator(images_path, masks_path, batch_size, IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES)\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\"unet_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "model.fit(train_generator,\n",
    "                validation_data=val_generator,\n",
    "                epochs=10,\n",
    "                callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "print(\"Model Building and Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00b3db-d1e8-443b-8caf-ec682276b31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
